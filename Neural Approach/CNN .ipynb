{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff28a853",
   "metadata": {},
   "source": [
    "# Most probable outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5520bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iDoc values have been sorted alphabetically and saved to 'sortedData.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel('shorterData.xlsx')\n",
    "\n",
    "# List of iDoc columns\n",
    "idoc_columns = ['iDoc02', 'iDoc03', 'iDoc04', 'iDoc05', 'iDoc06', 'iDoc07', 'iDoc08', 'iDoc09', 'iDoc10']\n",
    "\n",
    "def sort_idocs(row):\n",
    "    # Extract non-empty iDoc values into a list\n",
    "    idoc_values = [row[col] for col in idoc_columns if pd.notna(row[col]) and row[col] != '']\n",
    "    \n",
    "    # Sort the list alphabetically\n",
    "    sorted_idocs = sorted(idoc_values)\n",
    "    \n",
    "    # Fill remaining columns with empty strings if there are fewer than 9 iDoc values\n",
    "    sorted_idocs += [''] * (len(idoc_columns) - len(sorted_idocs))\n",
    "    \n",
    "    # Create a dictionary with sorted iDoc values assigned back to the iDoc columns\n",
    "    return pd.Series({col: sorted_idocs.pop(0) for col in idoc_columns})\n",
    "\n",
    "# Apply the sorting to each row and replace the iDoc columns with the sorted values\n",
    "df[idoc_columns] = df.apply(sort_idocs, axis=1)\n",
    "\n",
    "# Save the new sorted dataset to a new Excel file\n",
    "df.to_excel('alphaData.xlsx', index=False)\n",
    "\n",
    "print(\"iDoc values have been sorted alphabetically and saved to 'sortedData.xlsx'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c24c280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    ImpName            ExName Commodity Code  \\\n",
      "0  Lensbower, Gregory L Esq   US Clipper Inc.     7308100000   \n",
      "1            Mcmahan, Ben L   US Clipper Inc.     4820200000   \n",
      "2    Rowley/hansell Petetin   US Clipper Inc.     4820200000   \n",
      "3    Rowley/hansell Petetin   US Clipper Inc.     4820200000   \n",
      "4               Appbyte Ltd  Demo Company Ltd     0105993000   \n",
      "\n",
      "  CountryofOrigin_key                          iDoc02  \\\n",
      "0                  US                             NaN   \n",
      "1                  US                             NaN   \n",
      "2                  US                             NaN   \n",
      "3                  US                             NaN   \n",
      "4                  FR  C505~Guaranteenotrequired~CC~~   \n",
      "\n",
      "                     iDoc03          iDoc04 iDoc05 iDoc06 iDoc07 iDoc08  \\\n",
      "0                       NaN             NaN    NaN    NaN    NaN    NaN   \n",
      "1                       NaN             NaN    NaN    NaN    NaN    NaN   \n",
      "2                       NaN             NaN    NaN    NaN    NaN    NaN   \n",
      "3                       NaN             NaN    NaN    NaN    NaN    NaN   \n",
      "4  U110~Invoice~AE~Invoice~  C640~1204~AE~~    NaN    NaN    NaN    NaN   \n",
      "\n",
      "  iDoc09 iDoc10  \n",
      "0    NaN    NaN  \n",
      "1    NaN    NaN  \n",
      "2    NaN    NaN  \n",
      "3    NaN    NaN  \n",
      "4    NaN    NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('shorterData.xlsx', dtype={'Commodity Code': str})\n",
    "\n",
    "# Define the iDoc columns\n",
    "idoc_columns = ['iDoc02', 'iDoc03', 'iDoc04', 'iDoc05', 'iDoc06', 'iDoc07', 'iDoc08', 'iDoc09', 'iDoc10']\n",
    "\n",
    "# Remove all whitespace from each entry in the iDoc columns\n",
    "for col in idoc_columns:\n",
    "    df[col] = df[col].str.replace(r'\\s+', '', regex=True)\n",
    "\n",
    "# Save the cleaned DataFrame back to a new Excel file\n",
    "df.to_excel('cleanedData.xlsx', index=False)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "535f3118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "105/105 [==============================] - 1s 3ms/step - loss: 5.5562 - accuracy: 0.0149 - val_loss: 5.3622 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 5.0338 - accuracy: 0.0921 - val_loss: 5.3262 - val_accuracy: 0.0120\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 4.5296 - accuracy: 0.1493 - val_loss: 4.9746 - val_accuracy: 0.0764\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 4.1441 - accuracy: 0.1707 - val_loss: 4.3728 - val_accuracy: 0.1533\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.7615 - accuracy: 0.1798 - val_loss: 3.7347 - val_accuracy: 0.3001\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.4423 - accuracy: 0.2103 - val_loss: 3.2311 - val_accuracy: 0.3764\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.1917 - accuracy: 0.2547 - val_loss: 2.9259 - val_accuracy: 0.3710\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.9343 - accuracy: 0.2695 - val_loss: 2.6854 - val_accuracy: 0.4035\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.8165 - accuracy: 0.2859 - val_loss: 2.5921 - val_accuracy: 0.4107\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.6776 - accuracy: 0.2998 - val_loss: 2.5167 - val_accuracy: 0.3410\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.4848 - accuracy: 0.2837 - val_loss: 2.4248 - val_accuracy: 0.3091\n",
      "Epoch 12/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.4654 - accuracy: 0.2929 - val_loss: 2.3200 - val_accuracy: 0.3355\n",
      "Epoch 13/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.3186 - accuracy: 0.3023 - val_loss: 2.3190 - val_accuracy: 0.3199\n",
      "Epoch 14/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.2192 - accuracy: 0.3050 - val_loss: 2.2038 - val_accuracy: 0.3349\n",
      "Epoch 15/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.2111 - accuracy: 0.3040 - val_loss: 2.2092 - val_accuracy: 0.2808\n",
      "Epoch 16/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.2124 - accuracy: 0.3088 - val_loss: 2.1658 - val_accuracy: 0.3307\n",
      "Epoch 17/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.1631 - accuracy: 0.3136 - val_loss: 2.1747 - val_accuracy: 0.2922\n",
      "Epoch 18/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.0724 - accuracy: 0.3113 - val_loss: 2.1500 - val_accuracy: 0.3476\n",
      "Epoch 19/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.1267 - accuracy: 0.3242 - val_loss: 2.1059 - val_accuracy: 0.3193\n",
      "Epoch 20/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.1041 - accuracy: 0.3179 - val_loss: 2.1314 - val_accuracy: 0.3091\n",
      "52/52 [==============================] - 0s 558us/step - loss: 2.1314 - accuracy: 0.3091\n",
      "Accuracy for iDoc02: 0.31\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayush/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "105/105 [==============================] - 1s 2ms/step - loss: 5.2042 - accuracy: 0.0223 - val_loss: 5.0098 - val_accuracy: 0.0090\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 4.3783 - accuracy: 0.0668 - val_loss: 4.9236 - val_accuracy: 0.0084\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.8140 - accuracy: 0.1175 - val_loss: 4.7029 - val_accuracy: 0.0192\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.3277 - accuracy: 0.1507 - val_loss: 4.2652 - val_accuracy: 0.1455\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.9548 - accuracy: 0.1722 - val_loss: 3.7644 - val_accuracy: 0.2634\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.5770 - accuracy: 0.1886 - val_loss: 3.3344 - val_accuracy: 0.2886\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.3001 - accuracy: 0.2113 - val_loss: 3.1033 - val_accuracy: 0.3115\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.1450 - accuracy: 0.2279 - val_loss: 2.9633 - val_accuracy: 0.3355\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.8177 - accuracy: 0.2500 - val_loss: 2.6836 - val_accuracy: 0.3668\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.6762 - accuracy: 0.2713 - val_loss: 2.5919 - val_accuracy: 0.3650\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.4761 - accuracy: 0.2893 - val_loss: 2.5561 - val_accuracy: 0.3716\n",
      "Epoch 12/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.3493 - accuracy: 0.3091 - val_loss: 2.4305 - val_accuracy: 0.3836\n",
      "Epoch 13/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.3731 - accuracy: 0.3152 - val_loss: 2.4305 - val_accuracy: 0.3933\n",
      "Epoch 14/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.3155 - accuracy: 0.3225 - val_loss: 2.3033 - val_accuracy: 0.4065\n",
      "Epoch 15/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2350 - accuracy: 0.3400 - val_loss: 2.2408 - val_accuracy: 0.4239\n",
      "Epoch 16/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1224 - accuracy: 0.3545 - val_loss: 2.1384 - val_accuracy: 0.4750\n",
      "Epoch 17/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1385 - accuracy: 0.3678 - val_loss: 2.1121 - val_accuracy: 0.4384\n",
      "Epoch 18/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1006 - accuracy: 0.3813 - val_loss: 2.0891 - val_accuracy: 0.4564\n",
      "Epoch 19/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1116 - accuracy: 0.3854 - val_loss: 1.9816 - val_accuracy: 0.4588\n",
      "Epoch 20/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.0653 - accuracy: 0.3953 - val_loss: 1.9613 - val_accuracy: 0.4438\n",
      "52/52 [==============================] - 0s 533us/step - loss: 1.9613 - accuracy: 0.4438\n",
      "Accuracy for iDoc03: 0.44\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayush/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "105/105 [==============================] - 1s 2ms/step - loss: 5.2746 - accuracy: 0.0170 - val_loss: 4.9996 - val_accuracy: 0.0024\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 4.4690 - accuracy: 0.0504 - val_loss: 5.0159 - val_accuracy: 0.0168\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.8519 - accuracy: 0.0829 - val_loss: 4.7940 - val_accuracy: 0.0481\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.4355 - accuracy: 0.0973 - val_loss: 4.4089 - val_accuracy: 0.1318\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.0724 - accuracy: 0.1081 - val_loss: 4.0063 - val_accuracy: 0.1504\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.6147 - accuracy: 0.1157 - val_loss: 3.7332 - val_accuracy: 0.1655\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.3733 - accuracy: 0.1288 - val_loss: 3.5538 - val_accuracy: 0.2178\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.1073 - accuracy: 0.1469 - val_loss: 3.4474 - val_accuracy: 0.2449\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.9878 - accuracy: 0.1820 - val_loss: 3.2407 - val_accuracy: 0.3147\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.7910 - accuracy: 0.2062 - val_loss: 3.1789 - val_accuracy: 0.3544\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.6839 - accuracy: 0.2290 - val_loss: 2.9943 - val_accuracy: 0.3797\n",
      "Epoch 12/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.5575 - accuracy: 0.2424 - val_loss: 2.9649 - val_accuracy: 0.4079\n",
      "Epoch 13/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.4544 - accuracy: 0.2886 - val_loss: 2.7036 - val_accuracy: 0.4537\n",
      "Epoch 14/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.5486 - accuracy: 0.3182 - val_loss: 2.6693 - val_accuracy: 0.4236\n",
      "Epoch 15/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.3558 - accuracy: 0.3303 - val_loss: 2.5516 - val_accuracy: 0.4555\n",
      "Epoch 16/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.3744 - accuracy: 0.3641 - val_loss: 2.5025 - val_accuracy: 0.4765\n",
      "Epoch 17/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2978 - accuracy: 0.3659 - val_loss: 2.5228 - val_accuracy: 0.4789\n",
      "Epoch 18/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2758 - accuracy: 0.3448 - val_loss: 2.5182 - val_accuracy: 0.4675\n",
      "Epoch 19/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2760 - accuracy: 0.3569 - val_loss: 2.4976 - val_accuracy: 0.4699\n",
      "Epoch 20/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2230 - accuracy: 0.3521 - val_loss: 2.4952 - val_accuracy: 0.4567\n",
      "52/52 [==============================] - 0s 514us/step - loss: 2.4952 - accuracy: 0.4567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayush/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for iDoc04: 0.46\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "105/105 [==============================] - 1s 2ms/step - loss: 5.1383 - accuracy: 0.0112 - val_loss: 4.8795 - val_accuracy: 6.0168e-04\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 4.4838 - accuracy: 0.0326 - val_loss: 4.9560 - val_accuracy: 0.0199\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.8771 - accuracy: 0.0474 - val_loss: 4.8949 - val_accuracy: 0.0319\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.4902 - accuracy: 0.0614 - val_loss: 4.5565 - val_accuracy: 0.0788\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.1007 - accuracy: 0.0737 - val_loss: 4.1536 - val_accuracy: 0.0945\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.7480 - accuracy: 0.0889 - val_loss: 3.9726 - val_accuracy: 0.1137\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.4925 - accuracy: 0.0883 - val_loss: 3.7984 - val_accuracy: 0.1270\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.1978 - accuracy: 0.0957 - val_loss: 3.7430 - val_accuracy: 0.1227\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.1035 - accuracy: 0.1139 - val_loss: 3.5149 - val_accuracy: 0.2377\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.8350 - accuracy: 0.1459 - val_loss: 3.4205 - val_accuracy: 0.2575\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.8120 - accuracy: 0.1774 - val_loss: 3.1264 - val_accuracy: 0.3773\n",
      "Epoch 12/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.6842 - accuracy: 0.2160 - val_loss: 3.0900 - val_accuracy: 0.3947\n",
      "Epoch 13/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.6398 - accuracy: 0.2429 - val_loss: 3.0235 - val_accuracy: 0.4633\n",
      "Epoch 14/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.5859 - accuracy: 0.2790 - val_loss: 3.1222 - val_accuracy: 0.4254\n",
      "Epoch 15/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.5189 - accuracy: 0.2847 - val_loss: 2.9118 - val_accuracy: 0.4489\n",
      "Epoch 16/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.4532 - accuracy: 0.2777 - val_loss: 2.9630 - val_accuracy: 0.4477\n",
      "Epoch 17/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.4959 - accuracy: 0.3107 - val_loss: 2.8575 - val_accuracy: 0.4434\n",
      "Epoch 18/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.3762 - accuracy: 0.3334 - val_loss: 2.6379 - val_accuracy: 0.4922\n",
      "Epoch 19/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.3217 - accuracy: 0.3470 - val_loss: 2.6018 - val_accuracy: 0.4934\n",
      "Epoch 20/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.3928 - accuracy: 0.3550 - val_loss: 2.5541 - val_accuracy: 0.4687\n",
      "52/52 [==============================] - 0s 522us/step - loss: 2.5541 - accuracy: 0.4687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayush/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for iDoc05: 0.47\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "105/105 [==============================] - 1s 2ms/step - loss: 5.1901 - accuracy: 0.0064 - val_loss: 5.3798 - val_accuracy: 0.0054\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 4.5814 - accuracy: 0.0211 - val_loss: 5.6346 - val_accuracy: 0.0030\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.8971 - accuracy: 0.0354 - val_loss: 5.4873 - val_accuracy: 0.0216\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.5625 - accuracy: 0.0432 - val_loss: 5.2259 - val_accuracy: 0.0505\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.2343 - accuracy: 0.0493 - val_loss: 4.9219 - val_accuracy: 0.0397\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.9536 - accuracy: 0.0525 - val_loss: 4.6825 - val_accuracy: 0.0457\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.5696 - accuracy: 0.0478 - val_loss: 4.5156 - val_accuracy: 0.0487\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.4538 - accuracy: 0.0537 - val_loss: 4.4388 - val_accuracy: 0.0469\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.3185 - accuracy: 0.0557 - val_loss: 4.3235 - val_accuracy: 0.0463\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.1580 - accuracy: 0.0575 - val_loss: 4.2996 - val_accuracy: 0.0457\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.9703 - accuracy: 0.0670 - val_loss: 4.0222 - val_accuracy: 0.1130\n",
      "Epoch 12/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.9212 - accuracy: 0.0937 - val_loss: 3.9288 - val_accuracy: 0.2188\n",
      "Epoch 13/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.7821 - accuracy: 0.1345 - val_loss: 3.7889 - val_accuracy: 0.2999\n",
      "Epoch 14/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.7837 - accuracy: 0.1641 - val_loss: 3.7035 - val_accuracy: 0.3269\n",
      "Epoch 15/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.7046 - accuracy: 0.1744 - val_loss: 3.5817 - val_accuracy: 0.3474\n",
      "Epoch 16/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.7171 - accuracy: 0.2107 - val_loss: 3.4717 - val_accuracy: 0.3930\n",
      "Epoch 17/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.6258 - accuracy: 0.2439 - val_loss: 3.3044 - val_accuracy: 0.4249\n",
      "Epoch 18/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.6672 - accuracy: 0.2832 - val_loss: 3.2842 - val_accuracy: 0.4303\n",
      "Epoch 19/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.6362 - accuracy: 0.3082 - val_loss: 3.1618 - val_accuracy: 0.4507\n",
      "Epoch 20/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.5164 - accuracy: 0.3176 - val_loss: 3.2503 - val_accuracy: 0.4555\n",
      "52/52 [==============================] - 0s 557us/step - loss: 3.2503 - accuracy: 0.4555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayush/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for iDoc06: 0.46\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "105/105 [==============================] - 1s 2ms/step - loss: 4.9932 - accuracy: 0.0126 - val_loss: 4.9302 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 4.0769 - accuracy: 0.0214 - val_loss: 5.1928 - val_accuracy: 0.0018\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.5077 - accuracy: 0.0300 - val_loss: 5.2326 - val_accuracy: 0.0342\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.1963 - accuracy: 0.0353 - val_loss: 4.9953 - val_accuracy: 0.0354\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.8137 - accuracy: 0.0350 - val_loss: 4.8380 - val_accuracy: 0.0384\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.6910 - accuracy: 0.0341 - val_loss: 4.6949 - val_accuracy: 0.0396\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.3393 - accuracy: 0.0365 - val_loss: 4.5808 - val_accuracy: 0.0342\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.1394 - accuracy: 0.0348 - val_loss: 4.5533 - val_accuracy: 0.0378\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.0316 - accuracy: 0.0389 - val_loss: 4.5711 - val_accuracy: 0.0348\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.8577 - accuracy: 0.0420 - val_loss: 4.4030 - val_accuracy: 0.0432\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.8119 - accuracy: 0.0439 - val_loss: 4.3890 - val_accuracy: 0.0432\n",
      "Epoch 12/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.7808 - accuracy: 0.0451 - val_loss: 4.3227 - val_accuracy: 0.0553\n",
      "Epoch 13/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.9240 - accuracy: 0.0468 - val_loss: 4.1725 - val_accuracy: 0.0823\n",
      "Epoch 14/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.6518 - accuracy: 0.0577 - val_loss: 4.1307 - val_accuracy: 0.0679\n",
      "Epoch 15/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.6113 - accuracy: 0.0658 - val_loss: 4.0342 - val_accuracy: 0.1429\n",
      "Epoch 16/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.6139 - accuracy: 0.0894 - val_loss: 3.9799 - val_accuracy: 0.1520\n",
      "Epoch 17/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.3973 - accuracy: 0.1143 - val_loss: 3.8291 - val_accuracy: 0.2468\n",
      "Epoch 18/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.3664 - accuracy: 0.1260 - val_loss: 3.7214 - val_accuracy: 0.2853\n",
      "Epoch 19/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.5379 - accuracy: 0.1471 - val_loss: 3.7294 - val_accuracy: 0.3165\n",
      "Epoch 20/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.5444 - accuracy: 0.1861 - val_loss: 3.6495 - val_accuracy: 0.3093\n",
      "53/53 [==============================] - 0s 513us/step - loss: 3.6495 - accuracy: 0.3093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayush/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for iDoc07: 0.31\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "105/105 [==============================] - 1s 2ms/step - loss: 4.7071 - accuracy: 0.0262 - val_loss: 3.9673 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.6565 - accuracy: 0.0236 - val_loss: 4.2513 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.0380 - accuracy: 0.0193 - val_loss: 4.3427 - val_accuracy: 0.0012\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.5036 - accuracy: 0.0244 - val_loss: 4.2890 - val_accuracy: 0.0030\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.0083 - accuracy: 0.0209 - val_loss: 4.2174 - val_accuracy: 0.0060\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.6989 - accuracy: 0.0209 - val_loss: 4.1126 - val_accuracy: 0.0048\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.7815 - accuracy: 0.0199 - val_loss: 3.9858 - val_accuracy: 0.0024\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.5549 - accuracy: 0.0221 - val_loss: 4.0019 - val_accuracy: 0.0060\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.6790 - accuracy: 0.0284 - val_loss: 4.0980 - val_accuracy: 0.0102\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.3278 - accuracy: 0.0276 - val_loss: 4.0632 - val_accuracy: 0.0048\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.3390 - accuracy: 0.0351 - val_loss: 4.0017 - val_accuracy: 0.0156\n",
      "53/53 [==============================] - 0s 484us/step - loss: 3.9673 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayush/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for iDoc08: 0.00\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "105/105 [==============================] - 1s 2ms/step - loss: 3.6195 - accuracy: 0.0513 - val_loss: 3.0371 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.5677 - accuracy: 0.0496 - val_loss: 3.2048 - val_accuracy: 5.9916e-04\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.0721 - accuracy: 0.0702 - val_loss: 3.1973 - val_accuracy: 5.9916e-04\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.8827 - accuracy: 0.0776 - val_loss: 3.1460 - val_accuracy: 0.0042\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.6732 - accuracy: 0.0825 - val_loss: 3.2653 - val_accuracy: 0.0491\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.8593 - accuracy: 0.0834 - val_loss: 3.4107 - val_accuracy: 0.0719\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.4793 - accuracy: 0.0841 - val_loss: 3.3770 - val_accuracy: 0.0695\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.8177 - accuracy: 0.0699 - val_loss: 3.4738 - val_accuracy: 0.0461\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.0923 - accuracy: 0.0773 - val_loss: 3.3904 - val_accuracy: 0.0881\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.5531 - accuracy: 0.0828 - val_loss: 3.3233 - val_accuracy: 0.1348\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.5176 - accuracy: 0.0910 - val_loss: 3.0950 - val_accuracy: 0.1839\n",
      "53/53 [==============================] - 0s 503us/step - loss: 3.0371 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayush/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for iDoc09: 0.00\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "105/105 [==============================] - 1s 2ms/step - loss: 2.5203 - accuracy: 0.1046 - val_loss: 2.2170 - val_accuracy: 0.0018\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.5588 - accuracy: 0.0937 - val_loss: 2.3384 - val_accuracy: 0.0024\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8302 - accuracy: 0.0894 - val_loss: 2.3519 - val_accuracy: 0.0114\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7031 - accuracy: 0.0946 - val_loss: 2.2626 - val_accuracy: 0.0436\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.1072 - val_loss: 2.1764 - val_accuracy: 0.1381\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.1155 - val_loss: 2.1420 - val_accuracy: 0.2104\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.1342 - val_loss: 2.1904 - val_accuracy: 0.1895\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.1587 - val_loss: 2.2828 - val_accuracy: 0.1243\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.1675 - val_loss: 2.0972 - val_accuracy: 0.1877\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.1841 - val_loss: 1.9913 - val_accuracy: 0.3246\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.2258 - val_loss: 1.8524 - val_accuracy: 0.3425\n",
      "Epoch 12/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.2614 - val_loss: 1.6773 - val_accuracy: 0.4620\n",
      "Epoch 13/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.2883 - val_loss: 1.5310 - val_accuracy: 0.5607\n",
      "Epoch 14/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.3545 - val_loss: 1.4561 - val_accuracy: 0.5941\n",
      "Epoch 15/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.4008 - val_loss: 1.2993 - val_accuracy: 0.6874\n",
      "Epoch 16/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.4472 - val_loss: 1.1640 - val_accuracy: 0.7573\n",
      "Epoch 17/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.5034 - val_loss: 1.0298 - val_accuracy: 0.8177\n",
      "Epoch 18/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.5637 - val_loss: 0.9452 - val_accuracy: 0.8512\n",
      "Epoch 19/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1641 - accuracy: 0.6159 - val_loss: 0.8270 - val_accuracy: 0.8757\n",
      "Epoch 20/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.6518 - val_loss: 0.7572 - val_accuracy: 0.9139\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.7572 - accuracy: 0.9139\n",
      "Accuracy for iDoc10: 0.91\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayush/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import joblib\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "df = pd.read_excel('alphaData.xlsx', dtype={'Commodity Code': str})\n",
    "df.fillna('Missing', inplace=True)  # Replace NaNs with 'Missing'\n",
    "df = df.astype(str)\n",
    "\n",
    "X = df[['ImpName', 'ExName', 'Commodity Code', 'CountryofOrigin_key']]\n",
    "y = df[['iDoc02', 'iDoc03', 'iDoc04', 'iDoc05', 'iDoc06', 'iDoc07', 'iDoc08', 'iDoc09', 'iDoc10']]\n",
    "\n",
    "# One-Hot Encoding with Unknown variable handling\n",
    "encoder_X = OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first')\n",
    "X_encoded = encoder_X.fit_transform(X)\n",
    "joblib.dump(encoder_X, 'onehot_encoder_X_with_unknown.pkl')\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the neural network model\n",
    "def build_complex_model(output_size):\n",
    "    model = Sequential([\n",
    "        Dense(256, input_dim=X_train.shape[1], activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(output_size, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Early stopping callback to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Dictionary to store models and label encoders\n",
    "models = {}\n",
    "label_encoders = {}\n",
    "\n",
    "# Train a model for each iDoc column\n",
    "for col in y_train.columns:\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # Replace missing values with 'Missing' before encoding\n",
    "    y_train[col] = y_train[col].replace('', 'Missing')\n",
    "    y_test[col] = y_test[col].replace('', 'Missing')\n",
    "    \n",
    "    # Fit the label encoder on the training data\n",
    "    y_train_encoded = le.fit_transform(y_train[col].astype(str))\n",
    "    \n",
    "    # Transform the test data, filtering out any rows where the label is unseen\n",
    "    valid_indices = y_test[col].isin(le.classes_)\n",
    "    y_test_filtered = y_test[col][valid_indices]\n",
    "    y_test_encoded = le.transform(y_test_filtered)\n",
    "    X_test_filtered = X_test[valid_indices]\n",
    "    \n",
    "    # Compute class weights to handle the \"Missing\" data weighting\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train_encoded),\n",
    "        y=y_train_encoded\n",
    "    )\n",
    "    class_weights_dict = dict(enumerate(class_weights))\n",
    "    \n",
    "    # Build the model\n",
    "    model = build_complex_model(output_size=len(le.classes_))\n",
    "    \n",
    "    # Train the model with early stopping and class weights\n",
    "    model.fit(X_train, y_train_encoded, \n",
    "              epochs=20, \n",
    "              batch_size=64, \n",
    "              validation_data=(X_test_filtered, y_test_encoded), \n",
    "              callbacks=[early_stopping],\n",
    "              class_weight=class_weights_dict)  # Include class weights here\n",
    "    \n",
    "    # Save the model and label encoders\n",
    "    model.save(f'nn_model_{col}.h5')\n",
    "    joblib.dump(le, f'label_encoder_{col}.pkl')\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test_filtered, y_test_encoded)\n",
    "    print(f\"Accuracy for {col}: {accuracy:.2f}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fab04921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predictions for iDoc02:\n",
      "  C119~4320~AE~TEST~: 0.3932\n",
      "  C505~GBCGU02511510000720200206120129~CC~~: 0.3113\n",
      "  C505~Guaranteenotrequired~CC~ ~: 0.1978\n",
      "  C505~GBCGU02511510000720200206120129~CC~ ~: 0.0184\n",
      "  C064~3211~AC~Test~: 0.0134\n",
      "------------------------------\n",
      "Predictions for iDoc03:\n",
      "  U110~Invoice~AE~Invoice~: 0.6505\n",
      "  C506~GBDPO3712600~~~: 0.2213\n",
      "  C505~Guaranteenotrequired~CC~ ~: 0.0565\n",
      "  C505~GBCGU55320273485220191113093459~CC~ ~: 0.0111\n",
      "  C672~Invoice~AE~test~: 0.0095\n",
      "------------------------------\n",
      "Predictions for iDoc04:\n",
      "  U110~Invoice~AE~Invoice~: 0.3889\n",
      "  Missing: 0.1674\n",
      "  N935~INV0003~AC~ ~: 0.0239\n",
      "  C506~GBDPO1108654~ ~ ~: 0.0228\n",
      "  C672~Invoice~AE~test~: 0.0177\n",
      "  Y053~3221~ ~test~: 0.0154\n",
      "  C506~GBDPO1108654~~~: 0.0146\n",
      "  N853~7655~AE~test~: 0.0129\n",
      "  Y922~3111~ ~test~: 0.0120\n",
      "  C601~GBIPO02511510000720200206120129~~~: 0.0114\n",
      "  C505~Guaranteenotrequired~CC~ ~: 0.0099\n",
      "  C601~ GBIPO89645889501520190613093448~~~: 0.0075\n",
      "  Y929~4542~ ~test~: 0.0067\n",
      "  Y123~2110~ ~test2~: 0.0066\n",
      "  Y900~3211~ ~test1~: 0.0058\n",
      "  C506~GBDPO3712600~~~: 0.0058\n",
      "  Y032~4444~ ~test~: 0.0058\n",
      "  C605~Return0001~AC~~: 0.0058\n",
      "  C514~GBEIR553202734852I20190613093448~ ~ ~: 0.0054\n",
      "  C506~GBDPO~ ~ ~: 0.0052\n",
      "  9120~2211~AE~test3~: 0.0051\n",
      "------------------------------\n",
      "Predictions for iDoc05:\n",
      "  Missing: 0.3777\n",
      "  Y032~4444~ ~test~: 0.0360\n",
      "  C505~Guaranteenotrequired~CC~ ~: 0.0323\n",
      "  U110~Invoice~AE~Invoice~: 0.0319\n",
      "  Y123~2110~ ~test2~: 0.0315\n",
      "  999L~1214~ ~test4~: 0.0295\n",
      "  Y926~3221~ ~test~: 0.0284\n",
      "  C506~GBDPO8351733~~~: 0.0280\n",
      "  N935~INV0001~AC~ ~: 0.0268\n",
      "  U110~3211~AE~test2~: 0.0194\n",
      "  Y923~ ~ ~Not a waste~: 0.0136\n",
      "  N935~inv5678~AC~ ~: 0.0124\n",
      "  Y950~2111~ ~test2~: 0.0118\n",
      "  C683~AAA~AE~BBB~: 0.0106\n",
      "  C517~GBCWP55320273485220190607191400~~~: 0.0106\n",
      "  C506~GBDPO8351733~ ~ ~: 0.0100\n",
      "  999L~4322~ ~test~: 0.0069\n",
      "  C506~GBDPO1108654~ ~ ~: 0.0069\n",
      "  C517~GBCWP02511510000720200206120129~~~: 0.0066\n",
      "  Y054~ ~ ~test~: 0.0062\n",
      "  N935~INV0004~AC~~: 0.0059\n",
      "  N935~INV0005~AC~~: 0.0058\n",
      "  Y053~3221~ ~test~: 0.0056\n",
      "------------------------------\n",
      "Predictions for iDoc06:\n",
      "  Missing: 0.2609\n",
      "  Y950~2111~ ~test2~: 0.0874\n",
      "  U110~Invoice~AE~Invoice~: 0.0805\n",
      "  Y053~3221~ ~test~: 0.0285\n",
      "  Y123~ ~ ~test3~: 0.0245\n",
      "  N935~INV001~AC~ ~: 0.0182\n",
      "  Y922~3111~ ~test~: 0.0162\n",
      "  Y032~4444~~test~: 0.0155\n",
      "  Y053~3221~~test~: 0.0150\n",
      "  Y926~3221~ ~test~: 0.0141\n",
      "  N853~7655~AE~test~: 0.0134\n",
      "  Y922~3111~~test~: 0.0133\n",
      "  N935~INV0003~AC~ ~: 0.0111\n",
      "  Y900~3211~ ~test1~: 0.0110\n",
      "  N853~3431~AE~~: 0.0098\n",
      "  C517~GBCWP20190901300020190924124251~~test~: 0.0090\n",
      "  U110~42232~AE~test~: 0.0090\n",
      "  Y900~ ~ ~Testing~: 0.0085\n",
      "  C505~Guaranteenotrequired~CC~ ~: 0.0083\n",
      "  C644~1210~AE~~: 0.0081\n",
      "  N935~INV0001~AC~~: 0.0081\n",
      "  C605~4322~AC~~: 0.0079\n",
      "  C604~321`~AC~~: 0.0078\n",
      "  C605~2311~AC~~: 0.0078\n",
      "  C606~8766~AC~~: 0.0078\n",
      "  Y929~4542~ ~test~: 0.0075\n",
      "  C644~3232~AE~~: 0.0067\n",
      "  Y900~4242~~test3~: 0.0061\n",
      "  Y929~ ~ ~test2~: 0.0060\n",
      "  Y123~2110~ ~test2~: 0.0059\n",
      "  Y937~Invoice~ ~Invoice~: 0.0057\n",
      "  N935~1/2022-12-12~AC~ ~: 0.0056\n",
      "  C505~GBCGU02511510000720200206120129~CC~ ~: 0.0054\n",
      "  C603~3222~AC~~: 0.0053\n",
      "  C516~GBTEA20190901400020191219231429~ ~ ~: 0.0052\n",
      "------------------------------\n",
      "Predictions for iDoc07:\n",
      "  Y053~3221~ ~test~: 0.1116\n",
      "  Missing: 0.0976\n",
      "  Y950~2111~ ~test2~: 0.0712\n",
      "  Y053~3221~~test~: 0.0572\n",
      "  Y123~2110~ ~test2~: 0.0443\n",
      "  U166~7644~AE~test~: 0.0354\n",
      "  C604~2321~AC~~: 0.0340\n",
      "  Y900~3211~ ~test1~: 0.0329\n",
      "  Y900~3211~~test1~: 0.0229\n",
      "  C676~GBCW120190901300020190924124251~~~: 0.0180\n",
      "  Y032~4444~ ~test~: 0.0173\n",
      "  Y123~ ~ ~test1~: 0.0165\n",
      "  C605~4422~AC~~: 0.0160\n",
      "  U166~qw~AE~qw~: 0.0151\n",
      "  Y950~ ~ ~test1~: 0.0146\n",
      "  C506~GBDPO8351733~~~: 0.0143\n",
      "  N935~INV0002~AC~ ~: 0.0141\n",
      "  Y900~ ~ ~Testing~: 0.0130\n",
      "  Y926~3221~ ~test~: 0.0129\n",
      "  C604~4242~AC~~: 0.0127\n",
      "  C604~1111~AC~~: 0.0124\n",
      "  C603~3443~AC~~: 0.0121\n",
      "  C601~GBIPO89645889501520190613093448~~~: 0.0119\n",
      "  U110~Invoice~AE~Invoice~: 0.0119\n",
      "  C672~4321~AC~~: 0.0118\n",
      "  N935~INV0002~AC~~: 0.0116\n",
      "  C603~2322~AC~~: 0.0111\n",
      "  C676~GBCW220190901300020190924124251~~~: 0.0105\n",
      "  C505~GBCGU0835173300020200828141500~CC~~: 0.0092\n",
      "  Y929~5321~~test~: 0.0089\n",
      "  Y926~ ~ ~test~: 0.0087\n",
      "  C603~4433~AC~~: 0.0084\n",
      "  N935~INV001~AC~~: 0.0083\n",
      "  C506~GBDPO3712600~~~: 0.0077\n",
      "  C604~3221~AC~~: 0.0077\n",
      "  C604~3222~AC~~: 0.0076\n",
      "  C604~23123~AC~~: 0.0075\n",
      "  C676~GBCWP20190901300020190924124251~~~: 0.0074\n",
      "  C603~3223~AC~~: 0.0072\n",
      "  Y929~ ~ ~test~: 0.0069\n",
      "  C517~GBCWP20190901300020190924124251~ ~ ~: 0.0068\n",
      "  C604~4221~AC~~: 0.0067\n",
      "  C604~3443~AC~~: 0.0065\n",
      "  C604~4333~AC~~: 0.0064\n",
      "  C604~8442~AC~~: 0.0063\n",
      "  N853~3431~AE~~: 0.0059\n",
      "  C605~1222~AC~~: 0.0054\n",
      "------------------------------\n",
      "Predictions for iDoc08:\n",
      "  C605~5543~AC~~: 0.0889\n",
      "  N935~INV001~AC~ ~: 0.0492\n",
      "  C518~GBCW120190901300020190924124251~~~: 0.0446\n",
      "  C605~4343~AC~~: 0.0402\n",
      "  C517~GBCWP20190901300020190924124251~ ~ ~: 0.0386\n",
      "  Y922~3422~~test~: 0.0378\n",
      "  C605~3443~AC~~: 0.0351\n",
      "  Y929~SDD~ ~SDRF~: 0.0336\n",
      "  N853~3431~AE~ ~: 0.0333\n",
      "  C605~3221~AC~~: 0.0289\n",
      "  Missing: 0.0284\n",
      "  Y053~3221~ ~test~: 0.0263\n",
      "  C606~3221~AC~~: 0.0262\n",
      "  C605~3330~AC~~: 0.0258\n",
      "  Y032~4444~~test~: 0.0252\n",
      "  C606~4444~AC~~: 0.0238\n",
      "  Y900~3211~~test1~: 0.0231\n",
      "  C605~3223~AC~~: 0.0229\n",
      "  C605~3222~AC~~: 0.0228\n",
      "  Y123~2110~ ~test2~: 0.0219\n",
      "  C644~3232~AE~~: 0.0217\n",
      "  C604~2223~AC~~: 0.0216\n",
      "  N853~3431~AE~~: 0.0216\n",
      "  Y900~ ~ ~test2~: 0.0207\n",
      "  U110~3222~AE~~: 0.0207\n",
      "  Y922~4433~~test~: 0.0203\n",
      "  N935~inv001~AC~ ~: 0.0197\n",
      "  N990~GBEUS89645889501520191113093111~~~: 0.0191\n",
      "  C679~4433~AE~~: 0.0184\n",
      "  C506~GBDPO3712600~~~: 0.0181\n",
      "  Y032~No Seal~~No Seal~: 0.0180\n",
      "  Y926~3221~ ~test~: 0.0178\n",
      "  Y900~3211~ ~test1~: 0.0171\n",
      "  Y054~ ~ ~asdasd~: 0.0166\n",
      "  Y950~2111~ ~test2~: 0.0164\n",
      "  C606~~AC~~: 0.0133\n",
      "  N935~inv001~AC~~: 0.0115\n",
      "  C506~GBDPO8351733~~~: 0.0110\n",
      "------------------------------\n",
      "Predictions for iDoc09:\n",
      "  Y950~2111~ ~test2~: 0.1517\n",
      "  Y123~ ~ ~test2~: 0.1216\n",
      "  Missing: 0.0928\n",
      "  C606~3332~AC~~: 0.0838\n",
      "  Y032~4444~~test~: 0.0713\n",
      "  Y922~3111~~test~: 0.0629\n",
      "  C606~1121~AC~~: 0.0566\n",
      "  Y123~ ~ ~asdasd~: 0.0463\n",
      "  C606~121231~AC~~: 0.0446\n",
      "  Y922~4344~~test~: 0.0411\n",
      "  N935~inv001~AC~~: 0.0395\n",
      "  C517~GBCWP20190901300020190924124251~~~: 0.0265\n",
      "  C604~1111~AC~~: 0.0257\n",
      "  C606~4222~AC~~: 0.0253\n",
      "  Y900~3211~~test1~: 0.0237\n",
      "  N990~GBEUS02511510000720200206120129~~~: 0.0214\n",
      "  C606~2222~AC~~: 0.0204\n",
      "  Y032~ ~ ~test4~: 0.0176\n",
      "  N935~1111~AC~~: 0.0171\n",
      "  Y032~4444~ ~test~: 0.0102\n",
      "------------------------------\n",
      "Predictions for iDoc10:\n",
      "  Missing: 0.8042\n",
      "  Y950~ ~ ~asdad~: 0.0525\n",
      "  Y922~3422~~test~: 0.0439\n",
      "  N935~1111~AC~~: 0.0327\n",
      "  Y032~4444~~test~: 0.0223\n",
      "  Y950~2111~ ~test2~: 0.0164\n",
      "  Y900~3211~~test1~: 0.0158\n",
      "  Y900~3211~ ~test1~: 0.0074\n",
      "  Y922~8755~~test~: 0.0050\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import joblib\n",
    "\n",
    "# Prediction with new unseen data\n",
    "def predict_new_data(new_data):\n",
    "    encoder_X = joblib.load('onehot_encoder_X_with_unknown.pkl')\n",
    "    idoc_columns = ['iDoc02', 'iDoc03', 'iDoc04', 'iDoc05', 'iDoc06', 'iDoc07', 'iDoc08', 'iDoc09', 'iDoc10']\n",
    "    \n",
    "    # One-Hot Encode the new data using the encoder\n",
    "    new_data_encoded = encoder_X.transform(new_data)\n",
    "    \n",
    "    predictions = {}\n",
    "    \n",
    "    # Iterate over each iDoc column to make predictions\n",
    "    for col in idoc_columns:\n",
    "        model = tf.keras.models.load_model(f'nn_model_{col}.h5')\n",
    "        le = joblib.load(f'label_encoder_{col}.pkl')\n",
    "        \n",
    "        # Make predictions\n",
    "        encoded_pred = model.predict(new_data_encoded)\n",
    "        prob_pred = encoded_pred[0]\n",
    "        \n",
    "        # Store the predictions sorted by probability\n",
    "        sorted_preds = sorted(zip(le.classes_, prob_pred), key=lambda item: item[1], reverse=True)\n",
    "        predictions[col] = sorted_preds\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "new_data = pd.DataFrame({\n",
    "    'ImpName': ['Appbyte Ltd'], \n",
    "    'ExName': ['Demo Company Ltd'], \n",
    "    'Commodity Code': ['8529101100'], \n",
    "    'CountryofOrigin_key': ['PL']\n",
    "})\n",
    "\n",
    "predictions = predict_new_data(new_data)\n",
    "if predictions:\n",
    "    for col, preds in predictions.items():\n",
    "        print(f\"Predictions for {col}:\")\n",
    "        for label, prob in preds:\n",
    "            if prob > 0.005:  \n",
    "                print(f\"  {label}: {prob:.4f}\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7954384f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "Top 5 Predictions for iDoc02:\n",
      "  C505~Guaranteenotrequired~CC~~: 0.5098\n",
      "  C506~GBDPO3712600~~~: 0.0476\n",
      "  1207~20231020~AG~~: 0.0266\n",
      "  1207~20230529~AG~~: 0.0227\n",
      "  1207~20240215~AG~~: 0.0196\n",
      "------------------------------\n",
      "Top 5 Predictions for iDoc03:\n",
      "  U110~Invoice~AE~Invoice~: 0.8049\n",
      "  9120~RefNumber~AE~Reason~: 0.0163\n",
      "  Y032~4444~~test~: 0.0146\n",
      "  C644~2133~AE~test1~: 0.0093\n",
      "  C506~GBDPO1108654~~~: 0.0083\n",
      "------------------------------\n",
      "Top 5 Predictions for iDoc04:\n",
      "  C119~4320~AE~TEST~: 0.7521\n",
      "  U110~Invoice~AE~Invoice~: 0.0746\n",
      "  Missing: 0.0513\n",
      "  C064~3211~AC~Test~: 0.0463\n",
      "  C672~Invoice~AE~test~: 0.0089\n",
      "------------------------------\n",
      "Top 5 Predictions for iDoc05:\n",
      "  Missing: 0.3074\n",
      "  C505~Guaranteeenotrequired~CC~~: 0.0632\n",
      "  Y926~3221~~test~: 0.0488\n",
      "  U110~Invoice~AE~Invoice~: 0.0403\n",
      "  C505~Guaranteenotrequired~CC~~: 0.0346\n",
      "------------------------------\n",
      "Top 5 Predictions for iDoc06:\n",
      "  Missing: 0.0974\n",
      "  Y922~3111~~test~: 0.0503\n",
      "  Y931~Invoice~~Invoice~: 0.0492\n",
      "  U110~Invoice~AE~Invoice~: 0.0343\n",
      "  999L~1214~~test4~: 0.0338\n",
      "------------------------------\n",
      "Top 5 Predictions for iDoc07:\n",
      "  Missing: 0.1769\n",
      "  Y053~3221~~test~: 0.1265\n",
      "  C683~AAA~AE~BBB~: 0.0353\n",
      "  999L~1214~~test4~: 0.0310\n",
      "  Y926~3221~~test~: 0.0293\n",
      "------------------------------\n",
      "Top 5 Predictions for iDoc08:\n",
      "  C676~GBEXW20190901300020190924124251~~~: 0.0595\n",
      "  C516~GBTEA20190901400020191219231429~~~: 0.0552\n",
      "  Y123~2110~~test2~: 0.0504\n",
      "  Y053~3221~~test~: 0.0477\n",
      "  9022~1214~~test4~: 0.0455\n",
      "------------------------------\n",
      "Top 5 Predictions for iDoc09:\n",
      "  C601~GBIPO02511510000720200206120129~~~: 0.0671\n",
      "  C601~GBIPO89645889501520190613093448~~~: 0.0543\n",
      "  C601~GBIPO896458895015I20190613093448~~IPO~: 0.0536\n",
      "  C604~3443~AC~~: 0.0513\n",
      "  C606~3221~AC~~: 0.0507\n",
      "------------------------------\n",
      "Top 5 Predictions for iDoc10:\n",
      "  Missing: 0.2629\n",
      "  9WKS~123123~AC~~: 0.1210\n",
      "  9WKS~CalSheet1~AC~~: 0.0845\n",
      "  C505~GBCGU02511510000720200206120129~CC~~: 0.0762\n",
      "  C019~GBOPO89645889501520190613093448~~~: 0.0753\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import joblib\n",
    "\n",
    "# Prediction with new unseen data\n",
    "def predict_new_data(new_data):\n",
    "    # Load the encoder and models\n",
    "    encoder_X = joblib.load('onehot_encoder_X_with_unknown.pkl')\n",
    "    idoc_columns = ['iDoc02', 'iDoc03', 'iDoc04', 'iDoc05', 'iDoc06', 'iDoc07', 'iDoc08', 'iDoc09', 'iDoc10']\n",
    "    \n",
    "    # One-Hot Encode the new data using the encoder\n",
    "    new_data_encoded = encoder_X.transform(new_data)\n",
    "    \n",
    "    predictions = {}\n",
    "    \n",
    "    # Iterate over each iDoc column to make predictions\n",
    "    for col in idoc_columns:\n",
    "        model = tf.keras.models.load_model(f'nn_model_{col}.h5')\n",
    "        le = joblib.load(f'label_encoder_{col}.pkl')\n",
    "        \n",
    "        # Make predictions\n",
    "        encoded_pred = model.predict(new_data_encoded)\n",
    "        prob_pred = encoded_pred[0]  # Assuming single data point for prediction\n",
    "        \n",
    "        # Store the predictions sorted by probability\n",
    "        sorted_preds = sorted(zip(le.classes_, prob_pred), key=lambda item: item[1], reverse=True)\n",
    "        predictions[col] = sorted_preds[:5]  # Only keep the top 5 predictions\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "new_data = pd.DataFrame({\n",
    "    'ImpName': ['Appbyte Ltd'], \n",
    "    'ExName': ['Demo Company Ltd'], \n",
    "    'Commodity Code': ['3917330010'], \n",
    "    'CountryofOrigin_key': ['PL']\n",
    "})\n",
    "\n",
    "predictions = predict_new_data(new_data)\n",
    "if predictions:\n",
    "    for col, preds in predictions.items():\n",
    "        print(f\"Top 5 Predictions for {col}:\")\n",
    "        for label, prob in preds:\n",
    "            if prob > 0.005:  \n",
    "                print(f\"  {label}: {prob:.4f}\")\n",
    "        print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1499c41f",
   "metadata": {},
   "source": [
    "# Accuracy with top 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfed2422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual iDoc02: 9120~2211~AE~test3~ was in the top 5 predictions\n",
      "Actual iDoc03: C505~GBCGU02511510000720200206120129~CC~ ~ was in the top 5 predictions\n",
      "Actual iDoc04: C506~GBDPO3712600~~ ~ was NOT in the top 5 predictions\n",
      "Actual iDoc05: C644~1210~AE~ ~ was in the top 5 predictions\n",
      "Actual iDoc06: N853~3431~AE~ ~ was in the top 5 predictions\n",
      "Actual iDoc07: Missing was NOT in the top 5 predictions\n",
      "Actual iDoc08: Missing was NOT in the top 5 predictions\n",
      "Actual iDoc09: Missing was NOT in the top 5 predictions\n",
      "Actual iDoc10: Missing was in the top 5 predictions\n",
      "Top-5 accuracy: 0.56\n",
      "Top 5 Predictions for iDoc02:\n",
      "  9120~2211~AE~test3~: 0.4262\n",
      "  1207~20230614 ~AG~~: 0.2208\n",
      "  1207~20230613 ~AG~~: 0.1626\n",
      "  C505~GBCGU02511510000720200206120129~CC~~: 0.0287\n",
      "  C505~GBCGU0835173300020200828141500~CC~ ~: 0.0149\n",
      "------------------------------\n",
      "Top 5 Predictions for iDoc03:\n",
      "  C505~Guaranteenotrequired~CC~ ~: 0.3996\n",
      "  C505~GBCGU02511510000720200206120129~CC~ ~: 0.0731\n",
      "  C506~GBDPO3712600~~~: 0.0607\n",
      "  C119~4320~AE~TEST~: 0.0440\n",
      "  C505~GBCGU0835173300020200828141500~CC~~: 0.0301\n",
      "------------------------------\n",
      "Top 5 Predictions for iDoc04:\n",
      "  C644~1210~AE~test~: 0.3555\n",
      "  N853~3431~AE~ ~: 0.2041\n",
      "  C644~1210~AE~ ~: 0.1754\n",
      "  C644~1210~AE~~: 0.1232\n",
      "  C506~GBDPO3712600~ ~ ~: 0.0273\n",
      "------------------------------\n",
      "Top 5 Predictions for iDoc05:\n",
      "  N935~INV0002~AC~ ~: 0.2740\n",
      "  N853~3431~AE~ ~: 0.2321\n",
      "  N853~3431~AE~~: 0.1810\n",
      "  C644~234234~AE~TEST~: 0.1350\n",
      "  C644~1210~AE~ ~: 0.0774\n",
      "------------------------------\n",
      "Top 5 Predictions for iDoc06:\n",
      "  Y929~4542~ ~test~: 0.3158\n",
      "  N935~INV0003~AC~ ~: 0.1906\n",
      "  N853~3431~AE~~: 0.1705\n",
      "  N853~3431~AE~ ~: 0.1296\n",
      "  N935~INV0001~AC~~: 0.1271\n",
      "------------------------------\n",
      "Top 5 Predictions for iDoc07:\n",
      "  N935~INV0003~AC~ ~: 0.9271\n",
      "  N853~3431~AE~~: 0.0278\n",
      "  N853~3431~AE~ ~: 0.0082\n",
      "  N935~INV0003~AC~~: 0.0053\n",
      "------------------------------\n",
      "Top 5 Predictions for iDoc08:\n",
      "  Y922~4433~~test~: 0.0509\n",
      "  C605~3223~AC~~: 0.0488\n",
      "  N990~GBEUS89645889501520191113093111~~~: 0.0393\n",
      "  Y926~3221~ ~test~: 0.0386\n",
      "  Y123~2110~ ~test2~: 0.0385\n",
      "------------------------------\n",
      "Top 5 Predictions for iDoc09:\n",
      "  Y922~3111~~test~: 0.1101\n",
      "  N990~GBEUS02511510000720200206120129~~~: 0.1013\n",
      "  C606~2222~AC~~: 0.0759\n",
      "  Y032~ ~ ~test4~: 0.0648\n",
      "  Y123~ ~ ~test2~: 0.0598\n",
      "------------------------------\n",
      "Top 5 Predictions for iDoc10:\n",
      "  Missing: 0.7291\n",
      "  N935~1111~AC~~: 0.0566\n",
      "  Y922~8755~~test~: 0.0498\n",
      "  Y950~2111~ ~test2~: 0.0397\n",
      "  Y950~ ~ ~asdad~: 0.0328\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import joblib\n",
    "\n",
    "# Prediction with new unseen data\n",
    "def predict_new_data(new_data, actual_values):\n",
    "    encoder_X = joblib.load('onehot_encoder_X_with_unknown.pkl')\n",
    "    idoc_columns = ['iDoc02', 'iDoc03', 'iDoc04', 'iDoc05', 'iDoc06', 'iDoc07', 'iDoc08', 'iDoc09', 'iDoc10']\n",
    "    \n",
    "    # One-Hot Encode the new data using the encoder\n",
    "    new_data_encoded = encoder_X.transform(new_data)\n",
    "    \n",
    "    predictions = {}\n",
    "    \n",
    "    # Iterate over each iDoc column to make predictions\n",
    "    for col in idoc_columns:\n",
    "        model = tf.keras.models.load_model(f'nn_model_{col}.h5')\n",
    "        le = joblib.load(f'label_encoder_{col}.pkl')\n",
    "        \n",
    "        # Make predictions\n",
    "        encoded_pred = model.predict(new_data_encoded)\n",
    "        prob_pred = encoded_pred[0] \n",
    "        \n",
    "        # Store the predictions sorted by probability\n",
    "        sorted_preds = sorted(zip(le.classes_, prob_pred), key=lambda item: item[1], reverse=True)\n",
    "        predictions[col] = sorted_preds[:5]  # Only keep the top 5 predictions\n",
    "    \n",
    "    # Evaluate top-5 accuracy\n",
    "    correct_predictions = 0\n",
    "    total_predictions = len(idoc_columns)\n",
    "    \n",
    "    for col in idoc_columns:\n",
    "        top_preds = [label for label, prob in predictions[col]]\n",
    "        actual_value = actual_values[col].iloc[0]  # Get the actual value for the corresponding iDoc column\n",
    "        \n",
    "        if actual_value in top_preds:\n",
    "            correct_predictions += 1\n",
    "            print(f\"Actual {col}: {actual_value} was in the top 5 predictions\")\n",
    "        else:\n",
    "            print(f\"Actual {col}: {actual_value} was NOT in the top 5 predictions\")\n",
    "    \n",
    "    top_5_accuracy = correct_predictions / total_predictions\n",
    "    print(f\"Top-5 accuracy: {top_5_accuracy:.2f}\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Example usage:\n",
    "new_data = pd.DataFrame({\n",
    "    'ImpName': ['Appbyte Ltd'], \n",
    "    'ExName': ['Demo Company Ltd'], \n",
    "    'Commodity Code': ['204505900'], \n",
    "    'CountryofOrigin_key': ['US']\n",
    "})\n",
    "\n",
    "actual_values = pd.DataFrame({\n",
    "    'iDoc02': ['9120~2211~AE~test3~'],  \n",
    "    'iDoc03': ['C505~GBCGU02511510000720200206120129~CC~ ~'],\n",
    "    'iDoc04': ['C506~GBDPO3712600~~ ~'],\n",
    "    'iDoc05': ['C644~1210~AE~ ~'],\n",
    "    'iDoc06': ['N853~3431~AE~ ~'],\n",
    "    'iDoc07': ['Missing'],\n",
    "    'iDoc08': ['Missing'],\n",
    "    'iDoc09': ['Missing'],\n",
    "    'iDoc10': ['Missing']\n",
    "})\n",
    "\n",
    "predictions = predict_new_data(new_data, actual_values)\n",
    "if predictions:\n",
    "    for col, preds in predictions.items():\n",
    "        print(f\"Top 5 Predictions for {col}:\")\n",
    "        for label, prob in preds:\n",
    "            if prob > 0.005:  \n",
    "                print(f\"  {label}: {prob:.4f}\")\n",
    "        print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bb8b400-705e-4222-b5a5-f7c593d154ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/j8/s3w557v576v0dtnghwcjfxm40000gn/T/tmpcwgkxruh/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/j8/s3w557v576v0dtnghwcjfxm40000gn/T/tmpcwgkxruh/assets\n",
      "2024-09-13 12:12:24.328375: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-09-13 12:12:24.328399: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-09-13 12:12:24.328848: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/j8/s3w557v576v0dtnghwcjfxm40000gn/T/tmpcwgkxruh\n",
      "2024-09-13 12:12:24.329973: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-09-13 12:12:24.329978: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /var/folders/j8/s3w557v576v0dtnghwcjfxm40000gn/T/tmpcwgkxruh\n",
      "2024-09-13 12:12:24.332517: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2024-09-13 12:12:24.333520: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-09-13 12:12:24.374888: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /var/folders/j8/s3w557v576v0dtnghwcjfxm40000gn/T/tmpcwgkxruh\n",
      "2024-09-13 12:12:24.385624: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 56776 microseconds.\n",
      "2024-09-13 12:12:24.398418: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('nn_model_iDoc02.h5')\n",
    "\n",
    "# Convert the model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the converted model\n",
    "with open('nn_model_iDoc02.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b9a2b2-e08f-45cc-ab34-4c6ac0e8b65d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
